{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from torchvision.datasets.mnist import MNIST, FashionMNIST\n",
    "import scipy\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import cv2\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define parameters\n",
    "'''\n",
    "n_epochs = 30\n",
    "batch_size = 128\n",
    "n_steps = 200\n",
    "min_beta = 10 ** -4\n",
    "max_beta = 0.02\n",
    "step_for_FID = 3\n",
    "lr = 0.001\n",
    "n_real = 10  ## how many real images we want to sent in the Inception Model to get the FID score. i.e. 128 * n_real images will be sent. \n",
    "n_samples = 256  ## how many images we eant to generate\n",
    "n_feature = 192  ## the parameter of FID calcultion. Needs to be in the range[64, 192, 768, 2048]. The bigger it is, the better the preformance is. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"./ddpm_mnist.pt\"\n",
    "dataset_path = \"./datasets\"\n",
    "fig_path = \"./FID.png\"\n",
    "loss_path = \"./loss.png\"\n",
    "epoch_loss_path = \"./epoch_loss.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setting reproducibility\n",
    "'''\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rescale the images\n",
    "'''\n",
    "def scale_image(images, new_shape):\n",
    "    new_images = []\n",
    "    for image in images:\n",
    "        new_image = skimage.transform.resize(image, new_shape, 0)\n",
    "        new_image = cv2.normalize(new_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "        new_images.append(new_image)\n",
    "    return np.asarray(new_images, dtype=np.uint8)\n",
    "\n",
    "\n",
    "'''\n",
    "FID calculation\n",
    "'''\n",
    "def get_fid(images1: torch.Tensor, images2: torch.Tensor, n_feature=64) -> torch.Tensor:\n",
    "    new_size = (3, 299, 299)\n",
    "    fid = FrechetInceptionDistance(feature=n_feature)\n",
    "    real = images1.clone()\n",
    "    fake = images2.clone()\n",
    "    \n",
    "    # convert into numpy to resize\n",
    "    if type(real) is torch.Tensor:\n",
    "        real = real.detach().cpu().numpy()\n",
    "        \n",
    "    if type(fake) is torch.Tensor:\n",
    "        fake = fake.detach().cpu().numpy()\n",
    "        \n",
    "    # resize to (3, 299, 299)\n",
    "    images1 = scale_image(real, new_size)\n",
    "    images2 = scale_image(fake, new_size)\n",
    "    \n",
    "    # convert it back to tensor\n",
    "    images1 = torch.tensor(images1)\n",
    "    images2 = torch.tensor(images2)\n",
    "    \n",
    "    # update the fid with new tensor\n",
    "    print(\"\\nUpdating the fid calculator....\\n\")\n",
    "    fid.update(images1, real=True)\n",
    "    fid.update(images2, real=False)\n",
    "    \n",
    "    # get the fid score\n",
    "    score = fid.compute()\n",
    "    print(\"\\nThe current FID score = {}. \\n\".format(score))\n",
    "    fid.reset()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To generate new images, we start with random noise and let t go from \n",
    "T back to 0. At each step, we estimate the noise as eta_theta and apply\n",
    "the denoising function. Finally, extra noise is added as in Langevin \n",
    "dynamics. \n",
    "'''\n",
    "def generate_new_images(ddpm, n_samples=16, device=None, c=1, h=28, w=28):\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            device = ddpm.device\n",
    "\n",
    "        x = torch.randn(n_samples, c, h, w).to(device)\n",
    "\n",
    "        for idx, t in enumerate(list(range(ddpm.n_steps))[::-1]):\n",
    "            time_tensor = (torch.ones(n_samples, 1) * t).to(device).long()\n",
    "            eta_theta = ddpm.backward(x, time_tensor)\n",
    "            alpha_t = ddpm.alphas[t]\n",
    "            alpha_t_bar = ddpm.alpha_bars[t]\n",
    "            x = (1 / alpha_t.sqrt()) * (x - (1 - alpha_t) / (1 - alpha_t_bar).sqrt() * eta_theta)\n",
    "\n",
    "            if t > 0:\n",
    "                z = torch.randn(n_samples, c, h, w).to(device)\n",
    "                beta_t = ddpm.betas[t]\n",
    "                sigma_t = beta_t.sqrt()\n",
    "                x = x + sigma_t * z\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading the data (converting each image into a tensor and normalizing between [-1, 1])\n",
    "'''\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: (x - 0.5) * 2)]\n",
    ")\n",
    "ds_fn = MNIST\n",
    "dataset = ds_fn(dataset_path, download=True, train=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create DDPM model to save alpha and beta values and apply \n",
    "the forward process. \n",
    "'''\n",
    "# class DDPM\n",
    "class MyDDPM(nn.Module):\n",
    "    def __init__(self, network, n_steps=200, min_beta=10 ** -4, max_beta=0.02, device=None, image_chw=(1, 28, 28)):\n",
    "        super(MyDDPM, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.device = device\n",
    "        self.image_chw = image_chw\n",
    "        self.network = network.to(device)\n",
    "        self.betas = torch.linspace(min_beta, max_beta, n_steps).to(\n",
    "            device) \n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.tensor([torch.prod(self.alphas[:i + 1]) for i in range(len(self.alphas))]).to(device)\n",
    "\n",
    "    def forward(self, x0, t, eta=None):\n",
    "        n, c, h, w = x0.shape\n",
    "        a_bar = self.alpha_bars[t]\n",
    "\n",
    "        if eta is None:\n",
    "            eta = torch.randn(n, c, h, w).to(self.device)\n",
    "\n",
    "        noisy = a_bar.sqrt().reshape(n, 1, 1, 1) * x0 + (1 - a_bar).sqrt().reshape(n, 1, 1, 1) * eta\n",
    "        return noisy\n",
    "\n",
    "    def backward(self, x, t):\n",
    "        # Integrate the reverse process (U-Net). Use this to return the estimated noise. \n",
    "        return self.network(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create U-Net model to predict the noise in the images given \n",
    "the image and the current time step. First of all, we define \n",
    "a block that will keep spatial dimensionality unchanged. This\n",
    "block will be used at every level of U-Net. \n",
    "'''\n",
    "class MyBlock(nn.Module):\n",
    "    def __init__(self, shape, in_c, out_c, kernel_size=3, stride=1, padding=1, activation=None, normalize=True):\n",
    "        super(MyBlock, self).__init__()\n",
    "        self.ln = nn.LayerNorm(shape)\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size, stride, padding)\n",
    "        self.activation = nn.SiLU() if activation is None else activation\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ln(x) if self.normalize else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "'''\n",
    "After building the block, we use sinusoidal embedding and one layer\n",
    "of MLPs to keep our image-to-image model conditional on the current \n",
    "time step. \n",
    "'''\n",
    "def sinusoidal_embedding(n, d):\n",
    "    # Returns the standard positional embedding\n",
    "    embedding = torch.zeros(n, d)\n",
    "    wk = torch.tensor([1 / 10_000 ** (2 * j / d) for j in range(d)])\n",
    "    wk = wk.reshape((1, d))\n",
    "    t = torch.arange(n).reshape((n, 1))\n",
    "    embedding[:,::2] = torch.sin(t * wk[:,::2])\n",
    "    embedding[:,1::2] = torch.cos(t * wk[:,::2])\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "'''\n",
    "Create a small utility function to generate a one-layer MLP which\n",
    "will be used to map positional embeddings.\n",
    "'''\n",
    "def _make_te(self, dim_in, dim_out):\n",
    "  return nn.Sequential(\n",
    "    nn.Linear(dim_in, dim_out),\n",
    "    nn.SiLU(),\n",
    "    nn.Linear(dim_out, dim_out)\n",
    "  )\n",
    "\n",
    "\n",
    "'''\n",
    "For the details in U-Net, we have 3 down-sample parts, a bottleneck\n",
    "in the middle of the network, and 3 up-sample steps with the usual\n",
    "U-Net residual connections (concatenations). \n",
    "'''\n",
    "class MyUNet(nn.Module):\n",
    "    def __init__(self, n_steps=1000, time_emb_dim=100):\n",
    "        super(MyUNet, self).__init__()\n",
    "\n",
    "        # Sinusoidal embedding\n",
    "        self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
    "        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)\n",
    "        self.time_embed.requires_grad_(False)\n",
    "\n",
    "        # First half\n",
    "        self.te1 = self._make_te(time_emb_dim, 1)\n",
    "        self.b1 = nn.Sequential(\n",
    "            MyBlock((1, 28, 28), 1, 10),\n",
    "            MyBlock((10, 28, 28), 10, 10),\n",
    "            MyBlock((10, 28, 28), 10, 10)\n",
    "        )\n",
    "        self.down1 = nn.Conv2d(10, 10, 4, 2, 1)\n",
    "\n",
    "        self.te2 = self._make_te(time_emb_dim, 10)\n",
    "        self.b2 = nn.Sequential(\n",
    "            MyBlock((10, 14, 14), 10, 20),\n",
    "            MyBlock((20, 14, 14), 20, 20),\n",
    "            MyBlock((20, 14, 14), 20, 20)\n",
    "        )\n",
    "        self.down2 = nn.Conv2d(20, 20, 4, 2, 1)\n",
    "\n",
    "        self.te3 = self._make_te(time_emb_dim, 20)\n",
    "        self.b3 = nn.Sequential(\n",
    "            MyBlock((20, 7, 7), 20, 40),\n",
    "            MyBlock((40, 7, 7), 40, 40),\n",
    "            MyBlock((40, 7, 7), 40, 40)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(40, 40, 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(40, 40, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.te_mid = self._make_te(time_emb_dim, 40)\n",
    "        self.b_mid = nn.Sequential(\n",
    "            MyBlock((40, 3, 3), 40, 20),\n",
    "            MyBlock((20, 3, 3), 20, 20),\n",
    "            MyBlock((20, 3, 3), 20, 40)\n",
    "        )\n",
    "\n",
    "        # Second half\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(40, 40, 4, 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(40, 40, 2, 1)\n",
    "        )\n",
    "\n",
    "        self.te4 = self._make_te(time_emb_dim, 80)\n",
    "        self.b4 = nn.Sequential(\n",
    "            MyBlock((80, 7, 7), 80, 40),\n",
    "            MyBlock((40, 7, 7), 40, 20),\n",
    "            MyBlock((20, 7, 7), 20, 20)\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(20, 20, 4, 2, 1)\n",
    "        self.te5 = self._make_te(time_emb_dim, 40)\n",
    "        self.b5 = nn.Sequential(\n",
    "            MyBlock((40, 14, 14), 40, 20),\n",
    "            MyBlock((20, 14, 14), 20, 10),\n",
    "            MyBlock((10, 14, 14), 10, 10)\n",
    "        )\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(10, 10, 4, 2, 1)\n",
    "        self.te_out = self._make_te(time_emb_dim, 20)\n",
    "        self.b_out = nn.Sequential(\n",
    "            MyBlock((20, 28, 28), 20, 10),\n",
    "            MyBlock((10, 28, 28), 10, 10),\n",
    "            MyBlock((10, 28, 28), 10, 10, normalize=False)\n",
    "        )\n",
    "\n",
    "        self.conv_out = nn.Conv2d(10, 1, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = self.time_embed(t)\n",
    "        n = len(x)\n",
    "        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))  # (N, 10, 28, 28)\n",
    "        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))  # (N, 20, 14, 14)\n",
    "        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))  # (N, 40, 7, 7)\n",
    "\n",
    "        out_mid = self.b_mid(self.down3(out3) + self.te_mid(t).reshape(n, -1, 1, 1))  # (N, 40, 3, 3)\n",
    "\n",
    "        out4 = torch.cat((out3, self.up1(out_mid)), dim=1)  # (N, 80, 7, 7)\n",
    "        out4 = self.b4(out4 + self.te4(t).reshape(n, -1, 1, 1))  # (N, 20, 7, 7)\n",
    "\n",
    "        out5 = torch.cat((out2, self.up2(out4)), dim=1)  # (N, 40, 14, 14)\n",
    "        out5 = self.b5(out5 + self.te5(t).reshape(n, -1, 1, 1))  # (N, 10, 14, 14)\n",
    "\n",
    "        out = torch.cat((out1, self.up3(out5)), dim=1)  # (N, 20, 28, 28)\n",
    "        out = self.b_out(out + self.te_out(t).reshape(n, -1, 1, 1))  # (N, 1, 28, 28)\n",
    "\n",
    "        out = self.conv_out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_te(self, dim_in, dim_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(dim_in, dim_out),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim_out, dim_out)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Instantiate the DDPM model using our U-Net\n",
    "'''\n",
    "ddpm = MyDDPM(MyUNet(n_steps=n_steps),\n",
    "              n_steps=n_steps,\n",
    "              min_beta=min_beta,\n",
    "              max_beta=max_beta,\n",
    "              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implement Algorithm 1 to make the model learn how to denoise images, \n",
    "which corresponds to the training loop.\n",
    "'''\n",
    "def training_loop(ddpm, loader, n_epochs, optim, device, real_images, store_path=\"./ddpm_model.pt\", generate=True):\n",
    "    mse = nn.MSELoss()\n",
    "    best_loss = float(\"inf\")\n",
    "    n_steps = ddpm.n_steps\n",
    "    scores = []\n",
    "    loss_record = []\n",
    "    epoch_loss_record = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs), desc=f\"Training progress\", colour=\"#00ff00\"):\n",
    "        epoch_loss = 0.0\n",
    "        for step, batch in enumerate(tqdm(loader, leave=False, desc=f\"Epoch {epoch + 1}/{n_epochs}\", colour=\"#005500\")):\n",
    "            x0 = batch[0].to(device)\n",
    "            n = len(x0)\n",
    "            \n",
    "            # randomly choose timestep. \n",
    "            eta = torch.randn_like(x0).to(device)\n",
    "            t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "\n",
    "            # Add noise on the images (forward process). \n",
    "            noisy_imgs = ddpm(x0, t, eta)\n",
    "\n",
    "            # Estimate the noise added on the images.\n",
    "            eta_theta = ddpm.backward(noisy_imgs, t.reshape(n, -1))\n",
    "\n",
    "            # Use MSE to get the loss. \n",
    "            loss = mse(eta_theta, eta)\n",
    "            loss_record.append(loss.item())\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            epoch_loss += loss.item() * len(x0) / len(loader.dataset)\n",
    "            \n",
    "            #Visualize the loss\n",
    "            loss_t = np.asarray(loss_record, dtype='float32')\n",
    "            fig_loss = plt.figure()\n",
    "            plt.plot(loss_t)\n",
    "            plt.title(\"Loss\")\n",
    "            plt.xlabel(\"iteration\")\n",
    "            plt.ylabel(\"loss\")\n",
    "            plt.grid(visible=True)\n",
    "            plt.savefig(loss_path)\n",
    "            plt.close(fig_loss)\n",
    "            \n",
    "        # Visualize the epoch loss\n",
    "        epoch_loss_record.append([epoch+1, epoch_loss])\n",
    "        epoch_loss_t = np.asarray(epoch_loss_record, dtype='float32')\n",
    "        fig_epoch_loss = plt.figure()\n",
    "        plt.plot(epoch_loss_t[:, 0], epoch_loss_t[:, 1])\n",
    "        plt.title(\"Epoch loss\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.grid(visible=True)\n",
    "        plt.savefig(epoch_loss_path)\n",
    "        plt.close(fig_epoch_loss)\n",
    "            \n",
    "        # Generate images\n",
    "        if (epoch+1) % step_for_FID == 0:\n",
    "            if generate:\n",
    "                fake_images = generate_new_images(ddpm=ddpm, \n",
    "                                                device=device, \n",
    "                                                n_samples=n_samples)\n",
    "                scores.append([epoch+1, \n",
    "                            get_fid(images1=real_images, \n",
    "                                    images2=fake_images, \n",
    "                                    n_feature=n_feature)])\n",
    "                temp = np.asarray(scores, dtype='float32')\n",
    "                fig_fid = plt.figure()\n",
    "                plt.plot(temp[:, 0], temp[:, 1])\n",
    "                plt.title(\"FID Score\")\n",
    "                plt.xlabel(\"epoch\")\n",
    "                plt.ylabel(\"score\")\n",
    "                plt.grid(visible=True)\n",
    "                plt.savefig(fig_path)\n",
    "                plt.close(fig_fid)\n",
    "\n",
    "        log_string = f\"\\nLoss at epoch {epoch + 1}: {epoch_loss:.3f}\"\n",
    "\n",
    "        if best_loss > epoch_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(ddpm.state_dict(), store_path)\n",
    "            log_string += \" --> Best model ever (stored)\\n\"\n",
    "\n",
    "        print(log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prepare the real_images for calculating FID in training loop.\n",
    "'''\n",
    "print(\"\\nGenerating the real images.... \\n\")\n",
    "batches = []\n",
    "cnt = 0\n",
    "for batch in loader:\n",
    "    if (cnt == n_real):\n",
    "        break\n",
    "    batches.append(batch[0])\n",
    "    cnt += 1\n",
    "real = batches[0]\n",
    "for i in range(1, len(batches)):\n",
    "    real = torch.cat((real, batches[i]))\n",
    "print(\"\\nThe real images are prepared. \\n\")\n",
    "print(\"\\nThe shape of real images = {}. \\n\".format(real.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Start the training     \n",
    "'''\n",
    "print(\"\\nStart training......\\n\")\n",
    "training_loop(ddpm=ddpm,\n",
    "              loader=loader,\n",
    "              n_epochs=n_epochs,\n",
    "              optim=torch.optim.Adam(ddpm.parameters(), lr=1e-3),\n",
    "              device=device,\n",
    "              real_images=real,\n",
    "              generate=True,\n",
    "              store_path=model_path)\n",
    "print(\"\\nTraining is done. \\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
